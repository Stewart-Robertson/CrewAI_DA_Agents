# Using CrewAI to boost productivity in data analysis

This project uses CrewAI to create a team (or _crew_) of agents to:
* **Speed up and simplify** the process of data wrangling/analysis when presented with a new dataset
* Offer **strategies** to deal with any issues identified
* Develop preliminary **strategic insights** from the data
* Suggest areas for **further analysis**
* Use the results to create **business-ready presentations** using AI. Note that nothing has been changed by me in the presentations, so there are some oddities in the AI images (although I think they are very impressive for being made in seconds).

The project uses CrewAI for a number of reasons, but mainly because it is open source
and serves as a flexible, application-agnostic agent-building framework.

A visual representation of the project is below:

![Project Diagram](https://github.com/user-attachments/assets/b3edfc38-c619-4722-aaf8-b4ff3356b509)


## Project Structure

- `data/raw`: Raw data files
- `docs/`: README and requirements.txt. Note that requirements.txt defines what libraries agents will use when executing code
- `notebooks/`: Jupyter notebooks for analysis
- `generated code/`: Code generated by the agents
- `presentations/`: AI-generated presentations synthesised from the agents' data analysis
- `reports/`: Analysis reports categorized by type

## The Data
Two datasets were used to develop the project, and both were created using mockaroo [https://www.mockaroo.com]:
1. transaction_data_with_errors.csv - 1,000 rows x 10 columns, with missing data
2. Superannuation.csv - 1,000 rows x 20 columns, with missing data

## Cost
I estimate the cost to be around 0.3-0.4 USD to produce a presentation based on my own use, which was with a mixture of gpt-4o-mini and gpt-4.1-mini.

## Limitations
### API Limits
Using csv files with LLM API calls uses a lot of tokens. This project will exceed token limits for gpt-4o/4.1-mini when anything more than approx 700 lines x 20 columns
are read by an agent and sent to the API. As such, limiting how much of the file is read by each agent is necessary.

This also means that a comprehensive analysis of all the data isn't possible.
_The agents' output should serve as a baseline for further analysis and human-led insight generation._

### Validation
Working with LLMs can be unpredictable due to both their lack of determinism and capacity for hallucination. If this project were to be developed further, a focus would be on building in validation and evaluation functionality to ensure output is fully trustworthy.

## Setup

1. Create a virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

2. Install dependencies:
```bash
pip install -r docs/requirements.txt
```

NOTE: You will need to have Docker installed as CrewAI's CodeExecution tool runs code in a Docker environment.

## Usage

Run the main analysis notebook:
```bash
jupyter notebook notebooks/CrewAI_DA_Agents.ipynb
```
